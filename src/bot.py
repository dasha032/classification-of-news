import logging
import tensorflow as tf
import re
import pymorphy2
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import wordpunct_tokenize
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext, ConversationHandler
from telegram import ReplyKeyboardMarkup, ReplyKeyboardRemove
import pickle
import os
import numpy as np
import csv
from datetime import datetime

MODEL_PATH = "news_model_3 copy.keras"
model = tf.keras.models.load_model(MODEL_PATH)

TOKEN = ""
ALLOWED_USERS = {
    675684022: "admin",
}

nltk.download('stopwords')
nltk.download('punkt')
stop_words = set(stopwords.words('russian'))
morph = pymorphy2.MorphAnalyzer()

(
    CHOOSING_MODE,
    TESTING_MODE,
    TRAINING_MODE,
    STANDARD_MODE,
    CHOOSING_ROLE,
    AWAITING_TEXT,
    AWAITING_FEEDBACK,
    AWAITING_RATING,
    AWAITING_CORRECTION,
    AWAITING_LONGER_TEXT
) = range(10)

with open('C:/–î–∏–ø–ª–æ–º/tokenizer_3.pkl', 'rb') as f:
    tokenizer_data = pickle.load(f)

tokenizer = Tokenizer(num_words=30000, oov_token="<UNK>")
tokenizer.__dict__.update({
    'config': tokenizer_data['config'],
    'word_index': tokenizer_data['word_index'],
    'index_word': tokenizer_data['index_word']
})


def log_feedback(user_id: int, text: str, model_score: float, user_feedback: str, role: str):
    with open('feedback_log.csv', 'a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            user_id,
            role,
            text[:200],
            f"{model_score:.1f}%",
            user_feedback
        ])


def is_text_too_short(text: str, min_words: int = 20) -> bool:
    words = wordpunct_tokenize(text)
    return len(words) < min_words


def preprocess_text(text: str, max_len: int = 32) -> tf.Tensor:

    text = re.sub(r'\n', ' ', text)
    text = re.sub(r'[^\w\s]', ' ', text)

    tokens = wordpunct_tokenize(text.lower())
    processed_tokens = [
        morph.parse(word)[0].normal_form
        for word in tokens
        if word.isalpha() and word not in stop_words
    ]

    sequence = tokenizer.texts_to_sequences([' '.join(processed_tokens)])
    padded = pad_sequences(sequence, maxlen=max_len, padding='post')
    return tf.convert_to_tensor(padded, dtype=tf.int32)


async def start(update: Update, context: CallbackContext):
    reply_markup = ReplyKeyboardMarkup(
        [["üîç –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞", "üß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º", "üéì –†–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è"]],
        resize_keyboard=True,
        one_time_keyboard=True
    )
    await update.message.reply_text(
        "üîç –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:\n\n"
        "‚Ä¢ <b>–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞</b> - –æ–±—ã—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏\n"
        "‚Ä¢ <b>–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º</b> - –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏\n"
        "‚Ä¢ <b>–†–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è</b> - —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)",
        parse_mode='HTML',
        reply_markup=reply_markup
    )
    return CHOOSING_MODE


async def choose_mode(update: Update, context: CallbackContext):
    mode = update.message.text
    user_id = update.message.from_user.id

    if mode == "üéì –†–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è":
        if user_id not in ALLOWED_USERS:
            await update.message.reply_text(
                "‚õî –¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ä–µ–∂–∏–º",
                reply_markup=ReplyKeyboardRemove()
            )
            return await start(update, context)
        context.user_data['mode'] = 'training'
        await update.message.reply_text(
            "–†–µ–∂–∏–º –¥–æ–æ–±—É—á–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω. –ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏.",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_TEXT

    elif mode == "üß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º":
        context.user_data['mode'] = 'testing'
        await update.message.reply_text(
            "–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ü–µ–Ω–∏–≤–∞–π—Ç–µ –æ—Ç–≤–µ—Ç—ã –ø–æ —à–∫–∞–ª–µ –æ—Ç 1 –¥–æ 5.",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_TEXT

    else:
        context.user_data['mode'] = 'standard'
        await update.message.reply_text(
            "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏. –ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ –Ω–æ–≤–æ—Å—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_TEXT


async def handle_longer_text(update: Update, context: CallbackContext):
    text = update.message.text

    if is_text_too_short(text):
        await update.message.reply_text(
            "‚ö†Ô∏è –¢–µ–∫—Å—Ç –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–≤–æ—Å—Ç—å –¥–ª–∏–Ω–Ω–µ–µ (–º–∏–Ω–∏–º—É–º 10 —Å–ª–æ–≤)."
        )
        return AWAITING_LONGER_TEXT

    return await handle_text(update, context)


async def handle_text(update: Update, context: CallbackContext):
    text = update.message.text
    mode = context.user_data.get('mode', 'standard')

    if is_text_too_short(text):
        await update.message.reply_text(
            "‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å (–º–∏–Ω–∏–º—É–º 10 —Å–ª–æ–≤)."
        )
        return AWAITING_LONGER_TEXT

    try:
        processed = preprocess_text(text)
        prediction = model.predict(processed)
        confidence = float(prediction[0][0]) * 100

        context.user_data['last_text'] = text
        context.user_data['last_prediction'] = confidence
        context.user_data['last_processed'] = processed.numpy()

        verdict = ("‚úÖ –í—ã—Å–æ–∫–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å" if confidence > 70 else
                   "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–∞ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è" if confidence > 30 else
                   "‚ùå –ù–∏–∑–∫–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å")

        if mode == 'testing':
            reply_markup = ReplyKeyboardMarkup(
                [["1", "2", "3", "4", "5"], ["üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å"]],
                resize_keyboard=True
            )
            message = (f"{verdict}\n–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {confidence:.1f}%\n"
                       "–û—Ü–µ–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å (1-5):")
            await update.message.reply_text(message, reply_markup=reply_markup)
            return AWAITING_RATING

        elif mode == 'training':
            reply_markup = ReplyKeyboardMarkup(
                [["‚úÖ –í–µ—Ä–Ω–æ", "‚úèÔ∏è –ò—Å–ø—Ä–∞–≤–∏—Ç—å"], ["üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å"]],
                resize_keyboard=True
            )
            message = (f"{verdict}\n–¢–µ–∫—É—â–∞—è –æ—Ü–µ–Ω–∫–∞: {confidence:.1f}%\n"
                       "–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∏–ª–∏ —É–∫–∞–∑–∞—Ç—å –≤–µ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É:")
            await update.message.reply_text(message, reply_markup=reply_markup)
            return AWAITING_FEEDBACK

        else:
            message = f"{verdict}\n–û—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏: {confidence:.1f}%"
            await update.message.reply_text(message)
            return AWAITING_TEXT

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}")
        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç.")
        return AWAITING_TEXT


async def handle_rating(update: Update, context: CallbackContext):
    feedback = update.message.text

    if feedback == "üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å":
        await update.message.reply_text("–ü—Ä–æ–ø—É—â–µ–Ω–æ", reply_markup=ReplyKeyboardRemove())
        return AWAITING_TEXT

    if feedback in ["1", "2", "3", "4", "5"]:
        log_feedback(
            user_id=update.message.from_user.id,
            text=context.user_data['last_text'],
            model_score=context.user_data['last_prediction'],
            user_feedback=f"RATING_{feedback}",
            role="user"
        )
        await update.message.reply_text(
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É! –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –±–æ—Ç–∞.",
            reply_markup=ReplyKeyboardRemove()
        )
    else:
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ—Ü–µ–Ω–∫—É –æ—Ç 1 –¥–æ 5",
            reply_markup=ReplyKeyboardMarkup(
                [["1", "2", "3", "4", "5"], ["üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å"]],
                resize_keyboard=True
            )
        )
        return AWAITING_RATING

    return AWAITING_TEXT


async def handle_feedback(update: Update, context: CallbackContext):
    feedback = update.message.text

    if feedback == "üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å":
        await update.message.reply_text("–ü—Ä–æ–ø—É—â–µ–Ω–æ", reply_markup=ReplyKeyboardRemove())
        return AWAITING_TEXT

    if feedback == "‚úÖ –í–µ—Ä–Ω–æ":
        log_feedback(
            user_id=update.message.from_user.id,
            text=context.user_data['last_text'],
            model_score=context.user_data['last_prediction'],
            user_feedback="VERIFIED",
            role="admin"
        )
        await update.message.reply_text(
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ!",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_TEXT

    elif feedback == "‚úèÔ∏è –ò—Å–ø—Ä–∞–≤–∏—Ç—å":
        await update.message.reply_text(
            "–£–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ (0-100):",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_CORRECTION
    else:
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞",
            reply_markup=ReplyKeyboardMarkup(
                [["‚úÖ –í–µ—Ä–Ω–æ", "‚úèÔ∏è –ò—Å–ø—Ä–∞–≤–∏—Ç—å"], ["üö´ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å"]],
                resize_keyboard=True
            )
        )
        return AWAITING_FEEDBACK


async def handle_correction(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id
    user_input = update.message.text.strip()

    try:
        correction = float(user_input.replace(',', '.'))
        if not 0 <= correction <= 100:
            raise ValueError("–ß–∏—Å–ª–æ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞")

        processed = context.user_data['last_processed']

        if processed.ndim == 3:
            processed = processed.reshape(processed.shape[0], -1)
        elif processed.ndim == 1:
            processed = processed.reshape(1, -1)

        model.fit(
            processed,
            np.array([[correction/100.0]]),
            epochs=1,
            verbose=0
        )
        model.save(MODEL_PATH)

        log_feedback(
            user_id=user_id,
            text=context.user_data['last_text'],
            model_score=context.user_data['last_prediction'],
            user_feedback=f"CORRECTED_TO_{correction}",
            role="admin"
        )

        await update.message.reply_text(
            f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞! –ù–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: {correction:.1f}%",
            reply_markup=ReplyKeyboardRemove()
        )
        return AWAITING_TEXT

    except ValueError as e:
        logging.error(f"–û—à–∏–±–∫–∞: {str(e)}")
        await update.message.reply_text(
            "‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ 0-100 (–ø—Ä–∏–º–µ—Ä: 50, 75.5 –∏–ª–∏ 100)\n"
            "–û—à–∏–±–∫–∞: " + str(e)
        )
        return AWAITING_CORRECTION


async def cancel(update: Update, context: CallbackContext) -> int:
    await update.message.reply_text(
        "–î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–∂–º–∏—Ç–µ /start –¥–ª—è –Ω–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.",
        reply_markup=ReplyKeyboardRemove()
    )
    return ConversationHandler.END


def main() -> None:
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

    application = Application.builder().token(TOKEN).build()

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler('start', start)],
        states={
            CHOOSING_MODE: [MessageHandler(filters.TEXT & ~filters.COMMAND, choose_mode)],
            AWAITING_TEXT: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)],
            AWAITING_RATING: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_rating)],
            AWAITING_FEEDBACK: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_feedback)],
            AWAITING_CORRECTION: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_correction)],
            AWAITING_LONGER_TEXT: [MessageHandler(
                filters.TEXT & ~filters.COMMAND, handle_longer_text)]
        },
        fallbacks=[CommandHandler('cancel', cancel)],
        allow_reentry=True
    )

    application.add_handler(conv_handler)

    if not os.path.exists('feedback_log.csv'):
        with open('feedback_log.csv', 'w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['Timestamp', 'User ID', 'Role',
                            'Text', 'Model Score', 'User Feedback'])

    application.run_polling()


if __name__ == "__main__":
    main()
